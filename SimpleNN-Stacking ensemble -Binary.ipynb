{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad02a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vecstack in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from vecstack) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from vecstack) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from vecstack) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\wintest\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcd4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e64e8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    130\n",
       "True     126\n",
       "Name: label, dtype: Int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('L:/Thesis/Dateset/FakenewsNet.csv', encoding='latin-1')\n",
    "\n",
    "df = df.astype(dtype={'title': 'string','url': 'string',\n",
    "                                'date_published': 'string','author_name': 'string',\n",
    "                                'content': 'string','label': 'string'})\n",
    "\n",
    "cols = ['countOfPosWord', 'countOfNegWord', 'NumberOfChar','NumberOfWords','NumberOfSentences','AvgCharPerWord','AvgWordPerSent','NumberOfUpCase','NumberOfPunctuatuion','Orgtitle_contentSim','TopicModellingSim','afinn_score','vader_score_compound','FREI','FKGL','ARI','GFI','CLI']\n",
    "data = pd.read_csv('L:/Thesis/Dateset/FakenewsNet.csv',  usecols = cols)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9419c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "numerical_data=list()\n",
    "for row in range(0,len(df)):\n",
    "  numerical_data.insert(row,data_scaled[row])\n",
    "df['numerical_features'] = numerical_data\n",
    "\n",
    "df = df.astype(dtype={'numerical_features': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d7a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_features']= df['title'] +' '+ df['content'] +' '+ df['author_name'] +' '+ df['date_published']\n",
    "df['Complete_Data'] = df['text_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0140c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DonePartOne\n",
      "DonePartTwo\n",
      "DonePartThree\n"
     ]
    }
   ],
   "source": [
    "for row in range(len(df)):\n",
    "  df['Complete_Data'][row] = re.sub(r\"won\\'t\", \"will not\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"can\\'t\", \"can not\", df['Complete_Data'][row])\n",
    "\n",
    "    # general\n",
    "  df['Complete_Data'][row] = re.sub(r\"n\\'t\", \" not\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'re\", \" are\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'s\", \" is\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'d\", \" would\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'ll\", \" will\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'t\", \" not\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'ve\", \" have\", df['Complete_Data'][row])\n",
    "  df['Complete_Data'][row] = re.sub(r\"\\'m\", \" am\", df['Complete_Data'][row])\n",
    "    \n",
    "print(\"DonePartOne\")\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "X = df['Complete_Data']\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "import re\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document= [word for word in document if word not in stop_words]\n",
    "    document = [ps.stem(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "    \n",
    "df['Complete_Data'] = documents\n",
    "print(\"DonePartTwo\")\n",
    "\n",
    "df['Complete_Data'] = documents\n",
    "\n",
    "df['Complete_Data'] = df['Complete_Data'] + df['numerical_features']\n",
    "\n",
    "for row in range(0,len(df)):\n",
    "    df['Complete_Data'][row] = re.sub(r'\\[',' ',df['Complete_Data'][row])\n",
    "    df['Complete_Data'][row] = re.sub(r'\\]',' ',df['Complete_Data'][row])\n",
    "    df['Complete_Data'][row] = re.sub(r'\\n',' ',df['Complete_Data'][row])\n",
    "    df['Complete_Data'][row] = re.sub(r'\\s+', ' ', df['Complete_Data'][row], flags=re.I)\n",
    "    \n",
    "    \n",
    "print(\"DonePartThree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f81fe948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  75\n",
      "max:  3967\n",
      "mean: 492.35\n",
      "mean + 2 *sigma: 1428.56\n",
      "1428\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "lenght=list()\n",
    "for row in range(0,len(df)):\n",
    "  lenght.insert(row , textstat.lexicon_count(df['Complete_Data'][row]))\n",
    "df['lenght']=lenght\n",
    "\n",
    "print('min: ', min(df['lenght']))\n",
    "print('max: ', max(df['lenght']))\n",
    "\n",
    "print('mean: {:.2f}'.format(np.mean(df['lenght'])))\n",
    "\n",
    "print('mean + 2 *sigma: {:.2f}'.format(np.mean(df['lenght'])+ 2.0 * np.std(df['lenght'])))\n",
    "\n",
    "\n",
    "max_features = int(np.mean(df['lenght'])+ 2.0 * np.std(df['lenght']))\n",
    "print(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "542f123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,4), max_features= max_features, stop_words={'english'})\n",
    "tfidf_vect_ngram.fit(df['Complete_Data'])\n",
    "X =  tfidf_vect_ngram.transform(df['Complete_Data'])\n",
    "\n",
    "X1=X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03181a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data=list()\n",
    "\n",
    "for row in range(0,len(df)):\n",
    "  combine_data.insert(row,np.hstack((X1[row],numerical_data[row])))\n",
    "df['combine_data'] = combine_data\n",
    "\n",
    "data = df['combine_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d020bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06841088, 0.        , 0.        , ..., 0.08650431, 0.15623724,\n",
       "       0.01882731])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a8ef4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "y = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c35a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20612 5153\n",
      "20612 5153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d801b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def compute_classweights(target):\n",
    "    \"\"\"\n",
    "    Computes the weights of the target values based on the samples\n",
    "    :param target: Y-target variable\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "    # compute class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(target),\n",
    "                                                     target)\n",
    "    \n",
    "    # make the class weight list into dictionary\n",
    "    weights = {}\n",
    "    \n",
    "    # enumerate the list\n",
    "    for index, weight in enumerate(class_weights):\n",
    "        weights[index] = weight\n",
    "        \n",
    "    return weights\n",
    "\n",
    "# Get the class weights for the target variable\n",
    "weights = compute_classweights(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f67f30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9901237414495427, 1: 1.0100752705033715}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c116a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b26cc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ensemble.RandomForestClassifier(max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=100),\n",
    "    \n",
    "    svm.SVC(C=10, gamma=0.1,kernel='rbf', verbose=True),\n",
    "    \n",
    "    xgboost.XGBClassifier(use_label_encoder =False, eval_metric='auc',learning_rate=0.1, \n",
    "                  objective='multi:softprob', num_class=5, max_depth= 20, n_estimators=1000),\n",
    "\n",
    "    linear_model.LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    \n",
    "    DecisionTreeClassifier(criterion='gini', min_samples_split=2, min_samples_leaf=1, max_depth=10, splitter='best')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671e1be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.91791190]\n",
      "    fold  1:  [0.91150786]\n",
      "    fold  2:  [0.90859693]\n",
      "    fold  3:  [0.91131380]\n",
      "    ----\n",
      "    MEAN:     [0.91233262] + [0.00342060]\n",
      "    FULL:     [0.91233262]\n",
      "\n",
      "model  1:     [SVC]\n",
      "[LibSVM]    fold  0:  [0.89908791]\n",
      "[LibSVM]    fold  1:  [0.89869979]\n",
      "[LibSVM]    fold  2:  [0.88957889]\n",
      "[LibSVM]    fold  3:  [0.89831166]\n",
      "    ----\n",
      "    MEAN:     [0.89641956] + [0.00395899]\n",
      "    FULL:     [0.89641956]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "    fold  0:  [0.92780904]\n",
      "    fold  1:  [0.93440714]\n",
      "    fold  2:  [0.92315156]\n",
      "    fold  3:  [0.93246652]\n",
      "    ----\n",
      "    MEAN:     [0.92945857] + [0.00435991]\n",
      "    FULL:     [0.92945857]\n",
      "\n",
      "model  3:     [LogisticRegression]\n",
      "    fold  0:  [0.85600621]\n",
      "    fold  1:  [0.85658840]\n",
      "    fold  2:  [0.84552688]\n",
      "    fold  3:  [0.85328935]\n",
      "    ----\n",
      "    MEAN:     [0.85285271] + [0.00440904]\n",
      "    FULL:     [0.85285271]\n",
      "\n",
      "model  4:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.88899670]\n",
      "    fold  1:  [0.88899670]\n",
      "    fold  2:  [0.88744421]\n",
      "    fold  3:  [0.88938482]\n",
      "    ----\n",
      "    MEAN:     [0.88870561] + [0.00074531]\n",
      "    FULL:     [0.88870561]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "S_train, S_test = stacking(models,                     # list of models\n",
    "                           x_train.tolist(), y_train, x_test.tolist(),   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=4,                  # number of folds\n",
    "                           stratified=True,            # stratified split for folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=0,             # ensure reproducibility\n",
    "                           verbose=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a35e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "790027d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:43] WARNING: ..\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Final prediction score: [0.93033185]\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                      n_estimators=100, max_depth=3)\n",
    "    \n",
    "# Fit 2nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa95cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.94      0.93      2650\n",
      "        True       0.94      0.92      0.93      2503\n",
      "\n",
      "    accuracy                           0.93      5153\n",
      "   macro avg       0.93      0.93      0.93      5153\n",
      "weighted avg       0.93      0.93      0.93      5153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a2a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2503  147]\n",
      " [ 212 2291]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusionmatrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusionmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afd66fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"xgb_stacking.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(model, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11a844b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b706d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c4acb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[21:08:40] d:\\bld\\xgboost-split_1619725139497\\work\\src\\data\\array_interface.h:139: Check failed: typestr.size() == 3 (2 vs. 3) : `typestr' should be of format <endian><type><size of type in bytes>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-001d53d98f1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Final prediction score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final prediction score: [%.8f]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mvalidate_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m             \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         )\n\u001b[0;32m   1217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m    824\u001b[0m                     \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                     \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                     \u001b[0mvalidate_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m                 )\n\u001b[0;32m    828\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_is_cupy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   1852\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1854\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1855\u001b[0m                 )\n\u001b[0;32m   1856\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [21:08:40] d:\\bld\\xgboost-split_1619725139497\\work\\src\\data\\array_interface.h:139: Check failed: typestr.size() == 3 (2 vs. 3) : `typestr' should be of format <endian><type><size of type in bytes>."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a534e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
